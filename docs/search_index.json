[["index.html", "Introduction to Machine Learning Preface Goal Philosophy Pre-requisites Key references Version history Contributor list License", " Introduction to Machine Learning Ehsan Karim 2021-11-14 Preface This document is a very basic introduction to machine learning. Goal Basic Machine Learning Terminologies (pre-reading) Supervised vs. Unsupervised Learning Algorithms Concepts Examples Over-Fitting, Measuring Performance and Model Tuning Overall steps Philosophy Code-first philosophy is adopted for this tutorial; demonstrating the analyses through one real data analysis problem used in the literature. This tutorial is not theory-focused, nor utilizes simulated data to explain the ideas. Given the focus on implementation, theory is beyond the scope of this tutorial. Pre-requisites The prerequisites are knowledge of multiple regression analysis and basic probability. Software demonstrations and codes will be provided in R, although proficiency in R is not required for understanding the concepts. Watch the tutorial video Key references Bi, Q., Goodman, K. E., Kaminsky, J., &amp; Lessler, J. (2019). What is machine learning? A primer for the epidemiologist. American journal of epidemiology, 188(12), 2222-2239. Kuhn M., Johnson K. (2013) [chapter 4] Over-Fitting and Model Tuning. In: Applied Predictive Modeling. Springer, New York, NY James, G., Witten, D., Hastie, T., &amp; Tibshirani, R. (2021). An introduction to statistical learning (2nd ed.). New York: springer. Vittinghoff, E., Glidden, D. V., Shiboski, S. C., &amp; McCulloch, C. E. (2011) [chapter 10] Predictor Selection. In: Regression methods in biostatistics: linear, logistic, survival, and repeated measures models. Springer. Version history Version 1.1 was created for course MEDI 504A 001 Emerging Topics in Experimental Medicine - EMRG TOP EXP MED, delivered on 2021W1. Some of the materials were initially prepared for Continuing Professional Development course, UBC Department of Medicine CPD event, November 3, 2020. Feel free to reach out for any comments, corrections, suggestions. Contributor list Ehsan Karim (SPPH, UBC) License The online version of this book is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. You may share, adapt the content and may distribute your contributions under the same license (CC BY-NC-SA 4.0), but you have to give appropriate credit, and cannot use material for the commercial purposes. How to cite Karim, ME (2021) Introduction to Machine Learning, URL: ehsanx.github.io/intro2ML/, (v1.1). "],["rhc-data-description.html", "Chapter 1 RHC data description 1.1 Data download 1.2 Creating Analytic data 1.3 Notations 1.4 Basic data exploration 1.5 Predictive vs. causal models", " Chapter 1 RHC data description Connors et al. (1996) published an article in JAMA. The article is about managing or guiding therapy for the critically ill patients in the intensive care unit. They considered a number of health-outcomes such as length of stay (hospital stay; measured continuously) death within certain period (death at any time up to 180 Days; measured as a binary variable) The original article was concerned about the association of right heart catheterization (RHC) use during the first 24 hours of care in the intensive care unit and the health-outcomes mentioned above, but we will use this data as a case study for our prediction modelling. 1.1 Data download Data is freely available from Vanderbilt Biostatistics, variable liste is available here, and the article is freely available from researchgate. # load the dataset ObsData &lt;- read.csv(&quot;https://hbiostat.org/data/repo/rhc.csv&quot;, header = TRUE) saveRDS(ObsData, file = &quot;data/rhc.RDS&quot;) 1.2 Creating Analytic data In this section, we show the process of preparing analytic data, so that the variables generally match with the way they were coded in the original article. Below we show the process of creating the analytic data. 1.2.1 Add column for outcome: length of stay # Length.of.Stay = date of discharge - study admission date # Length.of.Stay = date of death - study admission date # if date of discharge not available ObsData$Length.of.Stay &lt;- ObsData$dschdte - ObsData$sadmdte ObsData$Length.of.Stay[is.na(ObsData$Length.of.Stay)] &lt;- ObsData$dthdte[is.na(ObsData$Length.of.Stay)] - ObsData$sadmdte[is.na(ObsData$Length.of.Stay)] 1.2.2 Recoding column for outcome: death ObsData$death &lt;- ifelse(ObsData$death == &quot;Yes&quot;, 1, 0) 1.2.3 Remove unnecessary outcomes ObsData &lt;- dplyr::select(ObsData, !c(dthdte, lstctdte, dschdte, t3d30, dth30, surv2md1)) 1.2.4 Remove unnecessary and problematic variables ObsData &lt;- dplyr::select(ObsData, !c(sadmdte, ptid, X, adld3p, urin1, cat2)) 1.2.5 Basic data cleanup # convert all categorical variables to factors factors &lt;- c(&quot;cat1&quot;, &quot;ca&quot;, &quot;death&quot;, &quot;cardiohx&quot;, &quot;chfhx&quot;, &quot;dementhx&quot;, &quot;psychhx&quot;, &quot;chrpulhx&quot;, &quot;renalhx&quot;, &quot;liverhx&quot;, &quot;gibledhx&quot;, &quot;malighx&quot;, &quot;immunhx&quot;, &quot;transhx&quot;, &quot;amihx&quot;, &quot;sex&quot;, &quot;dnr1&quot;, &quot;ninsclas&quot;, &quot;resp&quot;, &quot;card&quot;, &quot;neuro&quot;, &quot;gastr&quot;, &quot;renal&quot;, &quot;meta&quot;, &quot;hema&quot;, &quot;seps&quot;, &quot;trauma&quot;, &quot;ortho&quot;, &quot;race&quot;, &quot;income&quot;) ObsData[factors] &lt;- lapply(ObsData[factors], as.factor) # convert RHC.use (RHC vs. No RHC) to a binary variable ObsData$RHC.use &lt;- ifelse(ObsData$swang1 == &quot;RHC&quot;, 1, 0) ObsData &lt;- dplyr::select(ObsData, !swang1) # Categorize the variables to match with the original paper ObsData$age &lt;- cut(ObsData$age, breaks=c(-Inf, 50, 60, 70, 80, Inf), right=FALSE) ObsData$race &lt;- factor(ObsData$race, levels=c(&quot;white&quot;,&quot;black&quot;,&quot;other&quot;)) ObsData$sex &lt;- as.factor(ObsData$sex) ObsData$sex &lt;- relevel(ObsData$sex, ref = &quot;Male&quot;) ObsData$cat1 &lt;- as.factor(ObsData$cat1) levels(ObsData$cat1) &lt;- c(&quot;ARF&quot;,&quot;CHF&quot;,&quot;Other&quot;,&quot;Other&quot;,&quot;Other&quot;, &quot;Other&quot;,&quot;Other&quot;,&quot;MOSF&quot;,&quot;MOSF&quot;) ObsData$ca &lt;- as.factor(ObsData$ca) levels(ObsData$ca) &lt;- c(&quot;Metastatic&quot;,&quot;None&quot;,&quot;Localized (Yes)&quot;) ObsData$ca &lt;- factor(ObsData$ca, levels=c(&quot;None&quot;, &quot;Localized (Yes)&quot;, &quot;Metastatic&quot;)) 1.2.6 Rename variables names(ObsData) &lt;- c(&quot;Disease.category&quot;, &quot;Cancer&quot;, &quot;Death&quot;, &quot;Cardiovascular&quot;, &quot;Congestive.HF&quot;, &quot;Dementia&quot;, &quot;Psychiatric&quot;, &quot;Pulmonary&quot;, &quot;Renal&quot;, &quot;Hepatic&quot;, &quot;GI.Bleed&quot;, &quot;Tumor&quot;, &quot;Immunosupperssion&quot;, &quot;Transfer.hx&quot;, &quot;MI&quot;, &quot;age&quot;, &quot;sex&quot;, &quot;edu&quot;, &quot;DASIndex&quot;, &quot;APACHE.score&quot;, &quot;Glasgow.Coma.Score&quot;, &quot;blood.pressure&quot;, &quot;WBC&quot;, &quot;Heart.rate&quot;, &quot;Respiratory.rate&quot;, &quot;Temperature&quot;, &quot;PaO2vs.FIO2&quot;, &quot;Albumin&quot;, &quot;Hematocrit&quot;, &quot;Bilirubin&quot;, &quot;Creatinine&quot;, &quot;Sodium&quot;, &quot;Potassium&quot;, &quot;PaCo2&quot;, &quot;PH&quot;, &quot;Weight&quot;, &quot;DNR.status&quot;, &quot;Medical.insurance&quot;, &quot;Respiratory.Diag&quot;, &quot;Cardiovascular.Diag&quot;, &quot;Neurological.Diag&quot;, &quot;Gastrointestinal.Diag&quot;, &quot;Renal.Diag&quot;, &quot;Metabolic.Diag&quot;, &quot;Hematologic.Diag&quot;, &quot;Sepsis.Diag&quot;, &quot;Trauma.Diag&quot;, &quot;Orthopedic.Diag&quot;, &quot;race&quot;, &quot;income&quot;, &quot;Length.of.Stay&quot;, &quot;RHC.use&quot;) saveRDS(ObsData, file = &quot;data/rhcAnalytic.RDS&quot;) 1.3 Notations Notations Example in RHC study \\(Y_1\\): Observed outcome length of stay \\(Y_2\\): Observed outcome death within 3 months \\(L\\): Covariates See below 1.4 Basic data exploration 1.4.1 Dimension and summary dim(ObsData) ## [1] 5735 52 #str(ObsData) 1.4.2 More comprehensive summary require(skimr) ## Loading required package: skimr ## Warning: package &#39;skimr&#39; was built under R version 4.1.1 skim(ObsData) Table 1.1: Data summary Name ObsData Number of rows 5735 Number of columns 52 _______________________ Column type frequency: factor 31 numeric 21 ________________________ Group variables None Variable type: factor skim_variable n_missing complete_rate ordered n_unique top_counts Disease.category 0 1 FALSE 4 ARF: 2490, MOS: 1626, Oth: 1163, CHF: 456 Cancer 0 1 FALSE 3 Non: 4379, Loc: 972, Met: 384 Death 0 1 FALSE 2 1: 3722, 0: 2013 Cardiovascular 0 1 FALSE 2 0: 4722, 1: 1013 Congestive.HF 0 1 FALSE 2 0: 4714, 1: 1021 Dementia 0 1 FALSE 2 0: 5171, 1: 564 Psychiatric 0 1 FALSE 2 0: 5349, 1: 386 Pulmonary 0 1 FALSE 2 0: 4646, 1: 1089 Renal 0 1 FALSE 2 0: 5480, 1: 255 Hepatic 0 1 FALSE 2 0: 5334, 1: 401 GI.Bleed 0 1 FALSE 2 0: 5550, 1: 185 Tumor 0 1 FALSE 2 0: 4419, 1: 1316 Immunosupperssion 0 1 FALSE 2 0: 4192, 1: 1543 Transfer.hx 0 1 FALSE 2 0: 5073, 1: 662 MI 0 1 FALSE 2 0: 5535, 1: 200 age 0 1 FALSE 5 [-I: 1424, [60: 1389, [70: 1338, [50: 917 sex 0 1 FALSE 2 Mal: 3192, Fem: 2543 DNR.status 0 1 FALSE 2 No: 5081, Yes: 654 Medical.insurance 0 1 FALSE 6 Pri: 1698, Med: 1458, Pri: 1236, Med: 647 Respiratory.Diag 0 1 FALSE 2 No: 3622, Yes: 2113 Cardiovascular.Diag 0 1 FALSE 2 No: 3804, Yes: 1931 Neurological.Diag 0 1 FALSE 2 No: 5042, Yes: 693 Gastrointestinal.Diag 0 1 FALSE 2 No: 4793, Yes: 942 Renal.Diag 0 1 FALSE 2 No: 5440, Yes: 295 Metabolic.Diag 0 1 FALSE 2 No: 5470, Yes: 265 Hematologic.Diag 0 1 FALSE 2 No: 5381, Yes: 354 Sepsis.Diag 0 1 FALSE 2 No: 4704, Yes: 1031 Trauma.Diag 0 1 FALSE 2 No: 5683, Yes: 52 Orthopedic.Diag 0 1 FALSE 2 No: 5728, Yes: 7 race 0 1 FALSE 3 whi: 4460, bla: 920, oth: 355 income 0 1 FALSE 4 Und: 3226, $11: 1165, $25: 893, &gt; $: 451 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist edu 0 1 11.68 3.15 0.00 10.00 12.00 13.00 30.00  DASIndex 0 1 20.50 5.32 11.00 16.06 19.75 23.43 33.00  APACHE.score 0 1 54.67 19.96 3.00 41.00 54.00 67.00 147.00  Glasgow.Coma.Score 0 1 21.00 30.27 0.00 0.00 0.00 41.00 100.00  blood.pressure 0 1 78.52 38.05 0.00 50.00 63.00 115.00 259.00  WBC 0 1 15.65 11.87 0.00 8.40 14.10 20.05 192.00  Heart.rate 0 1 115.18 41.24 0.00 97.00 124.00 141.00 250.00  Respiratory.rate 0 1 28.09 14.08 0.00 14.00 30.00 38.00 100.00  Temperature 0 1 37.62 1.77 27.00 36.09 38.09 39.00 43.00  PaO2vs.FIO2 0 1 222.27 114.95 11.60 133.31 202.50 316.62 937.50  Albumin 0 1 3.09 0.78 0.30 2.60 3.50 3.50 29.00  Hematocrit 0 1 31.87 8.36 2.00 26.10 30.00 36.30 66.19  Bilirubin 0 1 2.27 4.80 0.10 0.80 1.01 1.40 58.20  Creatinine 0 1 2.13 2.05 0.10 1.00 1.50 2.40 25.10  Sodium 0 1 136.77 7.66 101.00 132.00 136.00 142.00 178.00  Potassium 0 1 4.07 1.03 1.10 3.40 3.80 4.60 11.90  PaCo2 0 1 38.75 13.18 1.00 31.00 37.00 42.00 156.00  PH 0 1 7.39 0.11 6.58 7.34 7.40 7.46 7.77  Weight 0 1 67.83 29.06 0.00 56.30 70.00 83.70 244.00  Length.of.Stay 0 1 21.56 25.87 2.00 7.00 14.00 25.00 394.00  RHC.use 0 1 0.38 0.49 0.00 0.00 0.00 1.00 1.00  #require(rms) #describe(ObsData) 1.5 Predictive vs. causal models The focus of current document is predictive models (e.g., predicting a health outcome). The original article by Connors et al. (1996) focused on the association of right heart catheterization (RHC) use during the first 24 hours of care in the intensive care unit (exposure of primary interest) and the health-outcomes (such as length of stay). If the readers are interested about the causal models used in that article, they can refer to this tutorial. This data has been used in other articles in the literature within the advanced causal modelling context; for example Keele and Small (2021) and Keele and Small (2018). Readers can further consult this tutorial to understand those methods. References "],["prediction-from-continuous-outcome.html", "Chapter 2 Prediction from continuous outcome 2.1 Read previously saved data 2.2 Prediction for length of stay 2.3 Variables 2.4 Model 2.5 Measuring prediction error 2.6 Overfitting and Optimism", " Chapter 2 Prediction from continuous outcome In this chapter, we will talk about Regression that deals with prediction of continuous outcomes. We will use multiple linear regression to build the first prediction mode. 2.1 Read previously saved data ObsData &lt;- readRDS(file = &quot;data/rhcAnalytic.RDS&quot;) 2.2 Prediction for length of stay In this section, we show the regression fitting when outcome is continuous (length of stay). 2.3 Variables baselinevars &lt;- names(dplyr::select(ObsData, !c(Length.of.Stay,Death))) baselinevars ## [1] &quot;Disease.category&quot; &quot;Cancer&quot; &quot;Cardiovascular&quot; ## [4] &quot;Congestive.HF&quot; &quot;Dementia&quot; &quot;Psychiatric&quot; ## [7] &quot;Pulmonary&quot; &quot;Renal&quot; &quot;Hepatic&quot; ## [10] &quot;GI.Bleed&quot; &quot;Tumor&quot; &quot;Immunosupperssion&quot; ## [13] &quot;Transfer.hx&quot; &quot;MI&quot; &quot;age&quot; ## [16] &quot;sex&quot; &quot;edu&quot; &quot;DASIndex&quot; ## [19] &quot;APACHE.score&quot; &quot;Glasgow.Coma.Score&quot; &quot;blood.pressure&quot; ## [22] &quot;WBC&quot; &quot;Heart.rate&quot; &quot;Respiratory.rate&quot; ## [25] &quot;Temperature&quot; &quot;PaO2vs.FIO2&quot; &quot;Albumin&quot; ## [28] &quot;Hematocrit&quot; &quot;Bilirubin&quot; &quot;Creatinine&quot; ## [31] &quot;Sodium&quot; &quot;Potassium&quot; &quot;PaCo2&quot; ## [34] &quot;PH&quot; &quot;Weight&quot; &quot;DNR.status&quot; ## [37] &quot;Medical.insurance&quot; &quot;Respiratory.Diag&quot; &quot;Cardiovascular.Diag&quot; ## [40] &quot;Neurological.Diag&quot; &quot;Gastrointestinal.Diag&quot; &quot;Renal.Diag&quot; ## [43] &quot;Metabolic.Diag&quot; &quot;Hematologic.Diag&quot; &quot;Sepsis.Diag&quot; ## [46] &quot;Trauma.Diag&quot; &quot;Orthopedic.Diag&quot; &quot;race&quot; ## [49] &quot;income&quot; &quot;RHC.use&quot; 2.4 Model # adjust covariates out.formula1 &lt;- as.formula(paste(&quot;Length.of.Stay~ &quot;, paste(baselinevars, collapse = &quot;+&quot;))) saveRDS(out.formula1, file = &quot;data/form1.RDS&quot;) fit1 &lt;- lm(out.formula1, data = ObsData) require(Publish) adj.fit1 &lt;- publish(fit1, digits=1)$regressionTable out.formula1 ## Length.of.Stay ~ Disease.category + Cancer + Cardiovascular + ## Congestive.HF + Dementia + Psychiatric + Pulmonary + Renal + ## Hepatic + GI.Bleed + Tumor + Immunosupperssion + Transfer.hx + ## MI + age + sex + edu + DASIndex + APACHE.score + Glasgow.Coma.Score + ## blood.pressure + WBC + Heart.rate + Respiratory.rate + Temperature + ## PaO2vs.FIO2 + Albumin + Hematocrit + Bilirubin + Creatinine + ## Sodium + Potassium + PaCo2 + PH + Weight + DNR.status + Medical.insurance + ## Respiratory.Diag + Cardiovascular.Diag + Neurological.Diag + ## Gastrointestinal.Diag + Renal.Diag + Metabolic.Diag + Hematologic.Diag + ## Sepsis.Diag + Trauma.Diag + Orthopedic.Diag + race + income + ## RHC.use adj.fit1 ## Variable Units Coefficient CI.95 p-value ## 1 (Intercept) -76.8 [-139.4;-14.2] &lt;0.1 ## 2 Disease.category ARF Ref ## 3 CHF -5.6 [-9.0;-2.2] &lt;0.1 ## 4 Other -4.4 [-6.5;-2.3] &lt;0.1 ## 5 MOSF 2.9 [1.1;4.7] &lt;0.1 ## 6 Cancer None Ref ## 7 Localized (Yes) -7.8 [-15.7;0.1] &lt;0.1 ## 8 Metastatic -10.6 [-19.1;-2.1] &lt;0.1 ## 9 Cardiovascular 0 Ref ## 10 1 0.7 [-1.3;2.7] 0.5 ## 11 Congestive.HF 0 Ref ## 12 1 -1.8 [-3.9;0.4] 0.1 ## 13 Dementia 0 Ref ## 14 1 -1.3 [-3.6;1.1] 0.3 ## 15 Psychiatric 0 Ref ## 16 1 -0.5 [-3.1;2.2] 0.7 ## 17 Pulmonary 0 Ref ## 18 1 2.1 [0.1;4.0] &lt;0.1 ## 19 Renal 0 Ref ## 20 1 -6.9 [-10.8;-3.1] &lt;0.1 ## 21 Hepatic 0 Ref ## 22 1 -1.5 [-5.1;2.1] 0.4 ## 23 GI.Bleed 0 Ref ## 24 1 -5.1 [-9.7;-0.5] &lt;0.1 ## 25 Tumor 0 Ref ## 26 1 4.6 [-3.4;12.6] 0.3 ## 27 Immunosupperssion 0 Ref ## 28 1 0.1 [-1.4;1.7] 0.9 ## 29 Transfer.hx 0 Ref ## 30 1 1.2 [-0.9;3.2] 0.3 ## 31 MI 0 Ref ## 32 1 -1.7 [-5.3;2.0] 0.4 ## 33 age [-Inf,50) Ref ## 34 [50,60) 0.1 [-2.0;2.3] 0.9 ## 35 [60,70) -0.4 [-2.5;1.7] 0.7 ## 36 [70,80) -1.1 [-3.6;1.4] 0.4 ## 37 [80, Inf) -2.8 [-5.7;0.2] &lt;0.1 ## 38 sex Male Ref ## 39 Female 0.8 [-0.6;2.2] 0.2 ## 40 edu 0.0 [-0.2;0.3] 0.7 ## 41 DASIndex -0.1 [-0.2;0.1] 0.4 ## 42 APACHE.score -0.1 [-0.1;-0.0] &lt;0.1 ## 43 Glasgow.Coma.Score 0.0 [-0.0;0.0] 0.2 ## 44 blood.pressure -0.0 [-0.0;0.0] 0.2 ## 45 WBC 0.0 [-0.0;0.1] 0.2 ## 46 Heart.rate 0.0 [0.0;0.0] &lt;0.1 ## 47 Respiratory.rate -0.0 [-0.1;0.1] 1.0 ## 48 Temperature 0.5 [0.1;0.9] &lt;0.1 ## 49 PaO2vs.FIO2 -0.0 [-0.0;-0.0] &lt;0.1 ## 50 Albumin -2.6 [-3.5;-1.6] &lt;0.1 ## 51 Hematocrit -0.2 [-0.3;-0.1] &lt;0.1 ## 52 Bilirubin -0.1 [-0.3;0.1] 0.2 ## 53 Creatinine 0.5 [0.1;1.0] &lt;0.1 ## 54 Sodium 0.1 [0.0;0.2] &lt;0.1 ## 55 Potassium 0.3 [-0.3;1.0] 0.3 ## 56 PaCo2 0.1 [0.0;0.2] &lt;0.1 ## 57 PH 10.1 [2.2;17.9] &lt;0.1 ## 58 Weight 0.0 [-0.0;0.0] 1.0 ## 59 DNR.status No Ref ## 60 Yes -8.0 [-10.1;-5.8] &lt;0.1 ## 61 Medical.insurance Medicaid Ref ## 62 Medicare -0.5 [-3.2;2.2] 0.7 ## 63 Medicare &amp; Medicaid -2.4 [-5.8;0.9] 0.2 ## 64 No insurance -1.8 [-5.2;1.6] 0.3 ## 65 Private -2.1 [-4.6;0.4] 0.1 ## 66 Private &amp; Medicare -2.0 [-4.8;0.8] 0.2 ## 67 Respiratory.Diag No Ref ## 68 Yes 0.3 [-1.4;2.0] 0.7 ## 69 Cardiovascular.Diag No Ref ## 70 Yes 0.4 [-1.4;2.1] 0.7 ## 71 Neurological.Diag No Ref ## 72 Yes 3.5 [1.1;6.0] &lt;0.1 ## 73 Gastrointestinal.Diag No Ref ## 74 Yes 2.6 [0.3;4.8] &lt;0.1 ## 75 Renal.Diag No Ref ## 76 Yes 1.8 [-1.4;5.0] 0.3 ## 77 Metabolic.Diag No Ref ## 78 Yes -1.2 [-4.3;2.0] 0.5 ## 79 Hematologic.Diag No Ref ## 80 Yes -3.9 [-6.8;-0.9] &lt;0.1 ## 81 Sepsis.Diag No Ref ## 82 Yes 0.0 [-2.0;2.0] 1.0 ## 83 Trauma.Diag No Ref ## 84 Yes 1.1 [-5.9;8.2] 0.8 ## 85 Orthopedic.Diag No Ref ## 86 Yes 3.5 [-15.1;22.2] 0.7 ## 87 race white Ref ## 88 black -1.1 [-3.1;0.8] 0.2 ## 89 other 0.2 [-2.5;3.0] 0.9 ## 90 income $11-$25k Ref ## 91 $25-$50k 2.5 [0.2;4.7] &lt;0.1 ## 92 &gt; $50k 0.4 [-2.4;3.3] 0.8 ## 93 Under $11k -0.4 [-2.2;1.4] 0.6 ## 94 RHC.use 2.9 [1.4;4.4] &lt;0.1 2.4.1 Design Matrix Notations n is number of observations p is number of covariates Expands factors to a set of dummy variables. dim(ObsData) ## [1] 5735 52 length(attr(terms(out.formula1), &quot;term.labels&quot;)) ## [1] 50 head(model.matrix(fit1)) ## (Intercept) Disease.categoryCHF Disease.categoryOther Disease.categoryMOSF ## 1 1 0 1 0 ## 2 1 0 0 1 ## 3 1 0 0 1 ## 4 1 0 0 0 ## 5 1 0 0 1 ## 6 1 0 1 0 ## CancerLocalized (Yes) CancerMetastatic Cardiovascular1 Congestive.HF1 ## 1 1 0 0 0 ## 2 0 0 1 1 ## 3 1 0 0 0 ## 4 0 0 0 0 ## 5 0 0 0 0 ## 6 0 0 0 1 ## Dementia1 Psychiatric1 Pulmonary1 Renal1 Hepatic1 GI.Bleed1 Tumor1 ## 1 0 0 1 0 0 0 1 ## 2 0 0 0 0 0 0 0 ## 3 0 0 0 0 0 0 1 ## 4 0 0 0 0 0 0 0 ## 5 0 0 0 0 0 0 0 ## 6 0 0 1 0 0 0 0 ## Immunosupperssion1 Transfer.hx1 MI1 age[50,60) age[60,70) age[70,80) ## 1 0 0 0 0 0 1 ## 2 1 1 0 0 0 1 ## 3 1 0 0 0 0 0 ## 4 1 0 0 0 0 1 ## 5 0 0 0 0 1 0 ## 6 0 0 0 0 0 0 ## age[80, Inf) sexFemale edu DASIndex APACHE.score Glasgow.Coma.Score ## 1 0 0 12.000000 23.50000 46 0 ## 2 0 1 12.000000 14.75195 50 0 ## 3 0 1 14.069916 18.13672 82 0 ## 4 0 1 9.000000 22.92969 48 0 ## 5 0 0 9.945259 21.05078 72 41 ## 6 1 1 8.000000 17.50000 38 0 ## blood.pressure WBC Heart.rate Respiratory.rate Temperature ## 1 41 22.09765620 124 10 38.69531 ## 2 63 28.89843750 137 38 38.89844 ## 3 57 0.04999542 130 40 36.39844 ## 4 55 23.29687500 58 26 35.79688 ## 5 65 29.69921880 125 27 34.79688 ## 6 115 18.00000000 134 36 39.19531 ## PaO2vs.FIO2 Albumin Hematocrit Bilirubin Creatinine Sodium Potassium PaCo2 ## 1 68.0000 3.500000 58.00000 1.0097656 1.1999512 145 4.000000 40 ## 2 218.3125 2.599609 32.50000 0.6999512 0.5999756 137 3.299805 34 ## 3 275.5000 3.500000 21.09766 1.0097656 2.5996094 146 2.899902 16 ## 4 156.6562 3.500000 26.29688 0.3999634 1.6999512 117 5.799805 30 ## 5 478.0000 3.500000 24.00000 1.0097656 3.5996094 126 5.799805 17 ## 6 184.1875 3.099609 30.50000 1.0097656 1.3999023 138 5.399414 68 ## PH Weight DNR.statusYes Medical.insuranceMedicare ## 1 7.359375 64.69995 0 1 ## 2 7.329102 45.69998 0 0 ## 3 7.359375 0.00000 0 0 ## 4 7.459961 54.59998 0 0 ## 5 7.229492 78.39996 1 1 ## 6 7.299805 54.89999 0 1 ## Medical.insuranceMedicare &amp; Medicaid Medical.insuranceNo insurance ## 1 0 0 ## 2 0 0 ## 3 0 0 ## 4 0 0 ## 5 0 0 ## 6 0 0 ## Medical.insurancePrivate Medical.insurancePrivate &amp; Medicare ## 1 0 0 ## 2 0 1 ## 3 1 0 ## 4 0 1 ## 5 0 0 ## 6 0 0 ## Respiratory.DiagYes Cardiovascular.DiagYes Neurological.DiagYes ## 1 1 1 0 ## 2 0 0 0 ## 3 0 1 0 ## 4 1 0 0 ## 5 0 1 0 ## 6 1 0 0 ## Gastrointestinal.DiagYes Renal.DiagYes Metabolic.DiagYes Hematologic.DiagYes ## 1 0 0 0 0 ## 2 0 0 0 0 ## 3 0 0 0 0 ## 4 0 0 0 0 ## 5 0 0 0 0 ## 6 0 0 0 0 ## Sepsis.DiagYes Trauma.DiagYes Orthopedic.DiagYes raceblack raceother ## 1 0 0 0 0 0 ## 2 1 0 0 0 0 ## 3 0 0 0 0 0 ## 4 0 0 0 0 0 ## 5 0 0 0 0 0 ## 6 0 0 0 0 0 ## income$25-$50k income&gt; $50k incomeUnder $11k RHC.use ## 1 0 0 1 0 ## 2 0 0 1 1 ## 3 1 0 0 1 ## 4 0 0 0 0 ## 5 0 0 1 1 ## 6 0 0 1 0 dim(model.matrix(fit1)) ## [1] 5735 64 p &lt;- dim(model.matrix(fit1))[2] # intercept + slopes p ## [1] 64 2.4.2 Obtain prediction obs.y &lt;- ObsData$Length.of.Stay summary(obs.y) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 2.00 7.00 14.00 21.56 25.00 394.00 # Predict the above fit on ObsData data pred.y1 &lt;- predict(fit1, ObsData) summary(pred.y1) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -32.76 16.62 21.96 21.56 26.73 42.67 n &lt;- length(pred.y1) n ## [1] 5735 plot(obs.y,pred.y1) lines(lowess(obs.y,pred.y1), col = &quot;red&quot;) 2.5 Measuring prediction error Prediction error measures how well the model can predict the outcome for new data that were not used in developing the prediction model. Bias reduced for models with more variables Unimportant variables lead to noise / variability Bias variance trade-off / need penalization 2.5.1 R2 ref # Find SSE SSE &lt;- sum( (obs.y - pred.y1)^2 ) SSE ## [1] 3536398 # Find SST mean.obs.y &lt;- mean(obs.y) SST &lt;- sum( (obs.y - mean.obs.y)^2 ) SST ## [1] 3836690 # Find R2 R.2 &lt;- 1- SSE/SST R.2 ## [1] 0.07826832 require(caret) R2(pred.y1, obs.y) ## [1] 0.07826832 2.5.2 RMSE ref # Find RMSE Rmse &lt;- sqrt(SSE/(n-p)) Rmse ## [1] 24.97185 RMSE(pred.y1, obs.y) ## [1] 24.83212 2.5.3 Adj R2 ref # Find adj R2 adjR2 &lt;- 1-(1-R.2)*((n-1)/(n-p)) adjR2 ## [1] 0.06802866 2.6 Overfitting and Optimism Model usually performs very well in the empirical data where the model was fitted in the same data (optimistic) Model performs poorly in the new data (generalization is not as good) 2.6.1 Causes Model determined by data at hand without expert opinion Too many model parameters (\\(age\\), \\(age^2\\), \\(age^3\\)) / predictors Too small dataset (training) / data too noisy 2.6.2 Consequences Overestimation of effects of predictors Reduction in model performance in new observations 2.6.3 Proposed solutions We generally use procedures such as Internal validation sample splitting cross-validation bootstrap External validation Temporal Geographical Different data source to calculate same variable Different disease "],["data-spliting.html", "Chapter 3 Data spliting 3.1 Read previously saved data 3.2 Split the data 3.3 Train the model 3.4 Extract performance measures", " Chapter 3 Data spliting 3.1 Read previously saved data ObsData &lt;- readRDS(file = &quot;data/rhcAnalytic.RDS&quot;) ref ref # Using a seed to randomize in a reproducible way set.seed(123) require(caret) split&lt;-createDataPartition(y = ObsData$Length.of.Stay, p = 0.7, list = FALSE) str(split) ## int [1:4017, 1] 1 2 3 4 5 6 7 8 9 10 ... ## - attr(*, &quot;dimnames&quot;)=List of 2 ## ..$ : NULL ## ..$ : chr &quot;Resample1&quot; dim(split) ## [1] 4017 1 dim(ObsData)*.7 # approximate train data ## [1] 4014.5 36.4 dim(ObsData)*(1-.7) # approximate train data ## [1] 1720.5 15.6 3.2 Split the data # create train data train.data&lt;-ObsData[split,] dim(train.data) ## [1] 4017 52 # create test data test.data&lt;-ObsData[-split,] dim(test.data) ## [1] 1718 52 3.3 Train the model out.formula1 &lt;- readRDS(file = &quot;data/form1.RDS&quot;) out.formula1 ## Length.of.Stay ~ Disease.category + Cancer + Cardiovascular + ## Congestive.HF + Dementia + Psychiatric + Pulmonary + Renal + ## Hepatic + GI.Bleed + Tumor + Immunosupperssion + Transfer.hx + ## MI + age + sex + edu + DASIndex + APACHE.score + Glasgow.Coma.Score + ## blood.pressure + WBC + Heart.rate + Respiratory.rate + Temperature + ## PaO2vs.FIO2 + Albumin + Hematocrit + Bilirubin + Creatinine + ## Sodium + Potassium + PaCo2 + PH + Weight + DNR.status + Medical.insurance + ## Respiratory.Diag + Cardiovascular.Diag + Neurological.Diag + ## Gastrointestinal.Diag + Renal.Diag + Metabolic.Diag + Hematologic.Diag + ## Sepsis.Diag + Trauma.Diag + Orthopedic.Diag + race + income + ## RHC.use fit.train1&lt;-lm(out.formula1, data = train.data) # summary(fit.train1) 3.3.1 Function that gives performance measures perform &lt;- function(new.data, model.fit,model.formula=NULL, y.name = &quot;Y&quot;, digits=3){ # data dimension p &lt;- dim(model.matrix(model.fit))[2] # predicted value pred.y &lt;- predict(model.fit, new.data) # sample size n &lt;- length(pred.y) # outcome new.data.y &lt;- as.numeric(new.data[,y.name]) # R2 R2 &lt;- caret:::R2(pred.y, new.data.y) # adj R2 using alternate formula df.residual &lt;- n-p adjR2 &lt;- 1-(1-R2)*((n-1)/df.residual) # RMSE RMSE &lt;- caret:::RMSE(pred.y, new.data.y) # combine all of the results res &lt;- round(cbind(n,p,R2,adjR2,RMSE),digits) # returning object return(res) } 3.4 Extract performance measures perform(new.data=train.data, y.name = &quot;Length.of.Stay&quot;, model.fit=fit.train1) ## n p R2 adjR2 RMSE ## [1,] 4017 64 0.081 0.067 24.647 perform(new.data=test.data, y.name = &quot;Length.of.Stay&quot;, model.fit=fit.train1) ## n p R2 adjR2 RMSE ## [1,] 1718 64 0.056 0.02 25.488 perform(new.data=ObsData, y.name = &quot;Length.of.Stay&quot;, model.fit=fit.train1) ## n p R2 adjR2 RMSE ## [1,] 5735 64 0.073 0.063 24.902 "],["cross-validation.html", "Chapter 4 Cross-validation 4.1 Read previously saved data 4.2 k-fold cross-vaildation 4.3 Using caret package to automate", " Chapter 4 Cross-validation 4.1 Read previously saved data ObsData &lt;- readRDS(file = &quot;data/rhcAnalytic.RDS&quot;) out.formula1 &lt;- readRDS(file = &quot;data/form1.RDS&quot;) 4.2 k-fold cross-vaildation ref k = 5 dim(ObsData) ## [1] 5735 52 set.seed(567) # create folds (based on outcome) folds &lt;- createFolds(ObsData$Length.of.Stay, k = k, list = TRUE, returnTrain = TRUE) mode(folds) ## [1] &quot;list&quot; dim(ObsData)*4/5 # approximate training data size ## [1] 4588.0 41.6 dim(ObsData)/5 # approximate test data size ## [1] 1147.0 10.4 length(folds[[1]]) ## [1] 4588 length(folds[[5]]) ## [1] 4587 str(folds[[1]]) ## int [1:4588] 1 2 4 6 7 8 9 10 11 13 ... str(folds[[5]]) ## int [1:4587] 1 3 5 6 7 8 10 11 12 13 ... 4.2.1 Calculation for Fold 1 fold.index &lt;- 1 fold1.train.ids &lt;- folds[[fold.index]] head(fold1.train.ids) ## [1] 1 2 4 6 7 8 fold1.train &lt;- ObsData[fold1.train.ids,] fold1.test &lt;- ObsData[-fold1.train.ids,] out.formula1 ## Length.of.Stay ~ Disease.category + Cancer + Cardiovascular + ## Congestive.HF + Dementia + Psychiatric + Pulmonary + Renal + ## Hepatic + GI.Bleed + Tumor + Immunosupperssion + Transfer.hx + ## MI + age + sex + edu + DASIndex + APACHE.score + Glasgow.Coma.Score + ## blood.pressure + WBC + Heart.rate + Respiratory.rate + Temperature + ## PaO2vs.FIO2 + Albumin + Hematocrit + Bilirubin + Creatinine + ## Sodium + Potassium + PaCo2 + PH + Weight + DNR.status + Medical.insurance + ## Respiratory.Diag + Cardiovascular.Diag + Neurological.Diag + ## Gastrointestinal.Diag + Renal.Diag + Metabolic.Diag + Hematologic.Diag + ## Sepsis.Diag + Trauma.Diag + Orthopedic.Diag + race + income + ## RHC.use model.fit &lt;- lm(out.formula1, data = fold1.train) predictions &lt;- predict(model.fit, newdata = fold1.test) perform(new.data=fold1.test, y.name = &quot;Length.of.Stay&quot;, model.fit=model.fit) ## n p R2 adjR2 RMSE ## [1,] 1147 64 0.051 -0.004 24.86 4.2.2 Calculation for Fold 2 fold.index &lt;- 2 fold1.train.ids &lt;- folds[[fold.index]] head(fold1.train.ids) ## [1] 2 3 4 5 6 7 fold1.train &lt;- ObsData[fold1.train.ids,] fold1.test &lt;- ObsData[-fold1.train.ids,] model.fit &lt;- lm(out.formula1, data = fold1.train) predictions &lt;- predict(model.fit, newdata = fold1.test) perform(new.data=fold1.test, y.name = &quot;Length.of.Stay&quot;, model.fit=model.fit) ## n p R2 adjR2 RMSE ## [1,] 1147 64 0.066 0.011 24.714 4.3 Using caret package to automate ref # Using Caret package set.seed(504) # make a 5-fold CV ctrl&lt;-trainControl(method = &quot;cv&quot;,number = 5) # fit the model with formula = out.formula1 # use training method lm fit.cv&lt;-train(out.formula1, trControl = ctrl, data = ObsData, method = &quot;lm&quot;) fit.cv ## Linear Regression ## ## 5735 samples ## 50 predictor ## ## No pre-processing ## Resampling: Cross-Validated (5 fold) ## Summary of sample sizes: 4588, 4588, 4587, 4589, 4588 ## Resampling results: ## ## RMSE Rsquared MAE ## 25.05478 0.05980578 15.19515 ## ## Tuning parameter &#39;intercept&#39; was held constant at a value of TRUE # extract results from each test data summary.res &lt;- fit.cv$resample summary.res ## RMSE Rsquared MAE Resample ## 1 22.45199 0.06463766 14.52080 Fold1 ## 2 27.05869 0.06799916 15.29290 Fold2 ## 3 27.65794 0.06034484 15.51895 Fold3 ## 4 24.55357 0.03892546 15.47073 Fold4 ## 5 23.55174 0.06712180 15.17238 Fold5 mean(fit.cv$resample$Rsquared) ## [1] 0.05980578 sd(fit.cv$resample$Rsquared) ## [1] 0.01204451 mean(fit.cv$resample$RMSE) ## [1] 25.05478 sd(fit.cv$resample$RMSE) ## [1] 2.240366 "],["prediction-from-binary-outcome.html", "Chapter 5 Prediction from binary outcome 5.1 Read previously saved data 5.2 Outcome levels (factor) 5.3 Measuring prediction error 5.4 Variables 5.5 Model 5.6 Measuring prediction error 5.7 Cross-validation using caret 5.8 Variable selection", " Chapter 5 Prediction from binary outcome In this chapter, we will talk about Regression that deals with prediction of binary outcomes. We will use logistic regression to build the first prediction mode. 5.1 Read previously saved data ObsData &lt;- readRDS(file = &quot;data/rhcAnalytic.RDS&quot;) 5.2 Outcome levels (factor) Label Possible values of outcome levels(ObsData$Death)=c(&quot;No&quot;,&quot;Yes&quot;) # this is useful for caret # ref: https://tinyurl.com/caretbin class(ObsData$Death) ## [1] &quot;factor&quot; table(ObsData$Death) ## ## No Yes ## 2013 3722 5.3 Measuring prediction error Brier score Brier score 0 means perfect prediction, and close to zero means better prediction, 1 being the worst prediction. Less accurate forecasts get higher score in Brier score. AUC The area under a ROC curve is called as a c statistics. c being 0.5 means random prediction and 1 indicates perfect prediction 5.3.1 Prediction for death In this section, we show the regression fitting when outcome is binary (death). 5.4 Variables baselinevars &lt;- names(dplyr::select(ObsData, !c(Length.of.Stay,Death))) baselinevars ## [1] &quot;Disease.category&quot; &quot;Cancer&quot; &quot;Cardiovascular&quot; ## [4] &quot;Congestive.HF&quot; &quot;Dementia&quot; &quot;Psychiatric&quot; ## [7] &quot;Pulmonary&quot; &quot;Renal&quot; &quot;Hepatic&quot; ## [10] &quot;GI.Bleed&quot; &quot;Tumor&quot; &quot;Immunosupperssion&quot; ## [13] &quot;Transfer.hx&quot; &quot;MI&quot; &quot;age&quot; ## [16] &quot;sex&quot; &quot;edu&quot; &quot;DASIndex&quot; ## [19] &quot;APACHE.score&quot; &quot;Glasgow.Coma.Score&quot; &quot;blood.pressure&quot; ## [22] &quot;WBC&quot; &quot;Heart.rate&quot; &quot;Respiratory.rate&quot; ## [25] &quot;Temperature&quot; &quot;PaO2vs.FIO2&quot; &quot;Albumin&quot; ## [28] &quot;Hematocrit&quot; &quot;Bilirubin&quot; &quot;Creatinine&quot; ## [31] &quot;Sodium&quot; &quot;Potassium&quot; &quot;PaCo2&quot; ## [34] &quot;PH&quot; &quot;Weight&quot; &quot;DNR.status&quot; ## [37] &quot;Medical.insurance&quot; &quot;Respiratory.Diag&quot; &quot;Cardiovascular.Diag&quot; ## [40] &quot;Neurological.Diag&quot; &quot;Gastrointestinal.Diag&quot; &quot;Renal.Diag&quot; ## [43] &quot;Metabolic.Diag&quot; &quot;Hematologic.Diag&quot; &quot;Sepsis.Diag&quot; ## [46] &quot;Trauma.Diag&quot; &quot;Orthopedic.Diag&quot; &quot;race&quot; ## [49] &quot;income&quot; &quot;RHC.use&quot; 5.5 Model # adjust covariates out.formula2 &lt;- as.formula(paste(&quot;Death~ &quot;, paste(baselinevars, collapse = &quot;+&quot;))) saveRDS(out.formula2, file = &quot;data/form2.RDS&quot;) fit2 &lt;- glm(out.formula2, data = ObsData, family = binomial(link = &quot;logit&quot;)) require(Publish) adj.fit2 &lt;- publish(fit2, digits=1)$regressionTable out.formula2 ## Death ~ Disease.category + Cancer + Cardiovascular + Congestive.HF + ## Dementia + Psychiatric + Pulmonary + Renal + Hepatic + GI.Bleed + ## Tumor + Immunosupperssion + Transfer.hx + MI + age + sex + ## edu + DASIndex + APACHE.score + Glasgow.Coma.Score + blood.pressure + ## WBC + Heart.rate + Respiratory.rate + Temperature + PaO2vs.FIO2 + ## Albumin + Hematocrit + Bilirubin + Creatinine + Sodium + ## Potassium + PaCo2 + PH + Weight + DNR.status + Medical.insurance + ## Respiratory.Diag + Cardiovascular.Diag + Neurological.Diag + ## Gastrointestinal.Diag + Renal.Diag + Metabolic.Diag + Hematologic.Diag + ## Sepsis.Diag + Trauma.Diag + Orthopedic.Diag + race + income + ## RHC.use adj.fit2 ## Variable Units OddsRatio CI.95 p-value ## 1 Disease.category ARF Ref ## 2 CHF 1.0 [0.8;1.4] 0.8 ## 3 Other 1.6 [1.3;2.0] &lt;0.1 ## 4 MOSF 1.0 [0.9;1.2] 0.7 ## 5 Cancer None Ref ## 6 Localized (Yes) 6.6 [2.2;19.4] &lt;0.1 ## 7 Metastatic 26.4 [8.3;83.6] &lt;0.1 ## 8 Cardiovascular 0 Ref ## 9 1 1.3 [1.0;1.5] &lt;0.1 ## 10 Congestive.HF 0 Ref ## 11 1 1.6 [1.3;1.9] &lt;0.1 ## 12 Dementia 0 Ref ## 13 1 1.3 [1.0;1.6] &lt;0.1 ## 14 Psychiatric 0 Ref ## 15 1 0.9 [0.7;1.2] 0.6 ## 16 Pulmonary 0 Ref ## 17 1 1.0 [0.9;1.2] 0.7 ## 18 Renal 0 Ref ## 19 1 1.3 [0.9;1.9] 0.2 ## 20 Hepatic 0 Ref ## 21 1 1.3 [0.9;1.8] 0.1 ## 22 GI.Bleed 0 Ref ## 23 1 1.2 [0.8;1.9] 0.3 ## 24 Tumor 0 Ref ## 25 1 0.3 [0.1;0.9] &lt;0.1 ## 26 Immunosupperssion 0 Ref ## 27 1 1.2 [1.1;1.4] &lt;0.1 ## 28 Transfer.hx 0 Ref ## 29 1 0.8 [0.7;1.0] &lt;0.1 ## 30 MI 0 Ref ## 31 1 0.8 [0.6;1.2] 0.3 ## 32 age [-Inf,50) Ref ## 33 [50,60) 1.4 [1.2;1.8] &lt;0.1 ## 34 [60,70) 2.1 [1.7;2.5] &lt;0.1 ## 35 [70,80) 2.1 [1.6;2.6] &lt;0.1 ## 36 [80, Inf) 2.8 [2.1;3.8] &lt;0.1 ## 37 sex Male Ref ## 38 Female 0.8 [0.7;0.9] &lt;0.1 ## 39 edu 1.0 [1.0;1.0] 0.4 ## 40 DASIndex 1.0 [0.9;1.0] &lt;0.1 ## 41 APACHE.score 1.0 [1.0;1.0] &lt;0.1 ## 42 Glasgow.Coma.Score 1.0 [1.0;1.0] &lt;0.1 ## 43 blood.pressure 1.0 [1.0;1.0] 0.4 ## 44 WBC 1.0 [1.0;1.0] 0.2 ## 45 Heart.rate 1.0 [1.0;1.0] 0.7 ## 46 Respiratory.rate 1.0 [1.0;1.0] 0.8 ## 47 Temperature 0.9 [0.9;1.0] &lt;0.1 ## 48 PaO2vs.FIO2 1.0 [1.0;1.0] 0.3 ## 49 Albumin 1.0 [0.9;1.1] 0.6 ## 50 Hematocrit 1.0 [1.0;1.0] &lt;0.1 ## 51 Bilirubin 1.0 [1.0;1.1] &lt;0.1 ## 52 Creatinine 1.0 [1.0;1.0] 0.9 ## 53 Sodium 1.0 [1.0;1.0] 0.7 ## 54 Potassium 1.0 [0.9;1.1] 0.9 ## 55 PaCo2 1.0 [1.0;1.0] 0.3 ## 56 PH 1.1 [0.5;2.3] 0.9 ## 57 Weight 1.0 [1.0;1.0] &lt;0.1 ## 58 DNR.status No Ref ## 59 Yes 2.6 [2.0;3.3] &lt;0.1 ## 60 Medical.insurance Medicaid Ref ## 61 Medicare 1.6 [1.2;2.0] &lt;0.1 ## 62 Medicare &amp; Medicaid 1.4 [1.0;1.9] &lt;0.1 ## 63 No insurance 1.5 [1.1;2.0] &lt;0.1 ## 64 Private 1.3 [1.1;1.7] &lt;0.1 ## 65 Private &amp; Medicare 1.3 [1.0;1.7] &lt;0.1 ## 66 Respiratory.Diag No Ref ## 67 Yes 1.2 [1.0;1.4] &lt;0.1 ## 68 Cardiovascular.Diag No Ref ## 69 Yes 1.2 [1.0;1.4] &lt;0.1 ## 70 Neurological.Diag No Ref ## 71 Yes 1.5 [1.2;1.9] &lt;0.1 ## 72 Gastrointestinal.Diag No Ref ## 73 Yes 1.3 [1.1;1.6] &lt;0.1 ## 74 Renal.Diag No Ref ## 75 Yes 0.8 [0.6;1.1] 0.2 ## 76 Metabolic.Diag No Ref ## 77 Yes 1.0 [0.8;1.4] 0.8 ## 78 Hematologic.Diag No Ref ## 79 Yes 2.7 [2.0;3.8] &lt;0.1 ## 80 Sepsis.Diag No Ref ## 81 Yes 1.1 [0.9;1.4] 0.2 ## 82 Trauma.Diag No Ref ## 83 Yes 0.8 [0.4;1.4] 0.4 ## 84 Orthopedic.Diag No Ref ## 85 Yes 1.4 [0.2;8.1] 0.7 ## 86 race white Ref ## 87 black 1.0 [0.8;1.2] 0.9 ## 88 other 1.1 [0.8;1.4] 0.7 ## 89 income $11-$25k Ref ## 90 $25-$50k 0.8 [0.7;1.0] &lt;0.1 ## 91 &gt; $50k 0.8 [0.6;1.1] 0.2 ## 92 Under $11k 1.2 [1.0;1.4] &lt;0.1 ## 93 RHC.use 1.4 [1.2;1.6] &lt;0.1 5.6 Measuring prediction error 5.6.1 AUC require(pROC) ## Loading required package: pROC ## Type &#39;citation(&quot;pROC&quot;)&#39; for a citation. ## ## Attaching package: &#39;pROC&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## cov, smooth, var obs.y2&lt;-ObsData$Death pred.y2 &lt;- predict(fit2, type = &quot;response&quot;) rocobj &lt;- roc(obs.y2, pred.y2) ## Setting levels: control = No, case = Yes ## Setting direction: controls &lt; cases rocobj ## ## Call: ## roc.default(response = obs.y2, predictor = pred.y2) ## ## Data: pred.y2 in 2013 controls (obs.y2 No) &lt; 3722 cases (obs.y2 Yes). ## Area under the curve: 0.7682 plot(rocobj) auc(rocobj) ## Area under the curve: 0.7682 5.6.2 Brier Score require(DescTools) ## Loading required package: DescTools ## Warning: package &#39;DescTools&#39; was built under R version 4.1.1 ## ## Attaching package: &#39;DescTools&#39; ## The following objects are masked from &#39;package:caret&#39;: ## ## MAE, RMSE BrierScore(fit2) ## [1] 0.1812502 5.7 Cross-validation using caret 5.7.1 Basic setup # Using Caret package set.seed(504) # make a 5-fold CV require(caret) ctrl&lt;-trainControl(method = &quot;cv&quot;, number = 5, classProbs = TRUE, summaryFunction = twoClassSummary) # fit the model with formula = out.formula2 # use training method glm (have to specify family) fit.cv.bin&lt;-train(out.formula2, trControl = ctrl, data = ObsData, method = &quot;glm&quot;, family = binomial(), metric=&quot;ROC&quot;) fit.cv.bin ## Generalized Linear Model ## ## 5735 samples ## 50 predictor ## 2 classes: &#39;No&#39;, &#39;Yes&#39; ## ## No pre-processing ## Resampling: Cross-Validated (5 fold) ## Summary of sample sizes: 4587, 4589, 4587, 4589, 4588 ## Resampling results: ## ## ROC Sens Spec ## 0.7545115 0.4659618 0.8535653 5.7.2 Extract results from each test data summary.res &lt;- fit.cv.bin$resample summary.res ## ROC Sens Spec Resample ## 1 0.7444835 0.4739454 0.8630872 Fold1 ## 2 0.7544836 0.4502488 0.8561828 Fold2 ## 3 0.7786734 0.4739454 0.8738255 Fold3 ## 4 0.7350679 0.4626866 0.8373656 Fold4 ## 5 0.7598488 0.4689826 0.8373656 Fold5 mean(fit.cv.bin$resample$ROC) ## [1] 0.7545115 sd(fit.cv.bin$resample$ROC) ## [1] 0.01651437 5.7.3 More options ctrl&lt;-trainControl(method = &quot;cv&quot;, number = 5, classProbs = TRUE, summaryFunction = twoClassSummary) fit.cv.bin&lt;-train(out.formula2, trControl = ctrl, data = ObsData, method = &quot;glm&quot;, family = binomial(), metric=&quot;ROC&quot;, preProc = c(&quot;center&quot;, &quot;scale&quot;)) fit.cv.bin ## Generalized Linear Model ## ## 5735 samples ## 50 predictor ## 2 classes: &#39;No&#39;, &#39;Yes&#39; ## ## Pre-processing: centered (63), scaled (63) ## Resampling: Cross-Validated (5 fold) ## Summary of sample sizes: 4588, 4589, 4587, 4588, 4588 ## Resampling results: ## ## ROC Sens Spec ## 0.7548047 0.4629717 0.8530367 5.8 Variable selection We can also use stepwise regression that uses AIC as a criterion. set.seed(504) ctrl&lt;-trainControl(method = &quot;cv&quot;, number = 5, classProbs = TRUE, summaryFunction = twoClassSummary) fit.cv.bin.aic&lt;-train(out.formula2, trControl = ctrl, data = ObsData, method = &quot;glmStepAIC&quot;, direction =&quot;backward&quot;, family = binomial(), metric=&quot;ROC&quot;) fit.cv.bin.aic ## Generalized Linear Model with Stepwise Feature Selection ## ## 5735 samples ## 50 predictor ## 2 classes: &#39;No&#39;, &#39;Yes&#39; ## ## No pre-processing ## Resampling: Cross-Validated (5 fold) ## Summary of sample sizes: 4587, 4589, 4587, 4589, 4588 ## Resampling results: ## ## ROC Sens Spec ## 0.7540424 0.464468 0.8562535 summary(fit.cv.bin.aic) ## ## Call: ## NULL ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.8626 -0.9960 0.5052 0.8638 1.9578 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 1.0783624 0.7822168 1.379 0.168019 ## Disease.categoryOther 0.4495099 0.0919860 4.887 1.03e-06 ## `CancerLocalized (Yes)` 1.8942512 0.5501880 3.443 0.000575 ## CancerMetastatic 3.2703316 0.5858715 5.582 2.38e-08 ## Cardiovascular1 0.2386749 0.0939617 2.540 0.011081 ## Congestive.HF1 0.4539010 0.0971624 4.672 2.99e-06 ## Dementia1 0.2380213 0.1162903 2.047 0.040679 ## Hepatic1 0.3593093 0.1541762 2.331 0.019779 ## Tumor1 -1.2455123 0.5542624 -2.247 0.024630 ## Immunosupperssion1 0.2174294 0.0730803 2.975 0.002928 ## Transfer.hx1 -0.1849029 0.0945679 -1.955 0.050555 ## `age[50,60)` 0.3621248 0.0984288 3.679 0.000234 ## `age[60,70)` 0.6941924 0.0968434 7.168 7.60e-13 ## `age[70,80)` 0.6804939 0.1126637 6.040 1.54e-09 ## `age[80, Inf)` 0.9833851 0.1410563 6.972 3.13e-12 ## sexFemale -0.2805950 0.0653527 -4.294 1.76e-05 ## DASIndex -0.0429272 0.0062191 -6.902 5.11e-12 ## APACHE.score 0.0174907 0.0020017 8.738 &lt; 2e-16 ## Glasgow.Coma.Score 0.0093657 0.0012563 7.455 9.00e-14 ## WBC 0.0044518 0.0030090 1.479 0.139009 ## Temperature -0.0524703 0.0192757 -2.722 0.006487 ## PaO2vs.FIO2 0.0004741 0.0003054 1.552 0.120548 ## Hematocrit -0.0154796 0.0041593 -3.722 0.000198 ## Bilirubin 0.0313087 0.0094004 3.331 0.000867 ## Weight -0.0031548 0.0011213 -2.813 0.004902 ## DNR.statusYes 0.9347360 0.1326924 7.044 1.86e-12 ## Medical.insuranceMedicare 0.4764895 0.1257582 3.789 0.000151 ## `Medical.insuranceMedicare &amp; Medicaid` 0.3364916 0.1584757 2.123 0.033729 ## `Medical.insuranceNo insurance` 0.3711345 0.1568820 2.366 0.017996 ## Medical.insurancePrivate 0.2632637 0.1139805 2.310 0.020903 ## `Medical.insurancePrivate &amp; Medicare` 0.2819715 0.1313101 2.147 0.031764 ## Respiratory.DiagYes 0.1393974 0.0769026 1.813 0.069886 ## Cardiovascular.DiagYes 0.1804967 0.0836679 2.157 0.030982 ## Neurological.DiagYes 0.4320266 0.1189357 3.632 0.000281 ## Gastrointestinal.DiagYes 0.2819563 0.1092206 2.582 0.009836 ## Hematologic.DiagYes 0.9734424 0.1651363 5.895 3.75e-09 ## Sepsis.DiagYes 0.1539651 0.0943235 1.632 0.102614 ## `incomeUnder $11k` 0.2151437 0.0689392 3.121 0.001804 ## RHC.use 0.3552053 0.0713632 4.977 6.44e-07 ## ## (Intercept) ## Disease.categoryOther *** ## `CancerLocalized (Yes)` *** ## CancerMetastatic *** ## Cardiovascular1 * ## Congestive.HF1 *** ## Dementia1 * ## Hepatic1 * ## Tumor1 * ## Immunosupperssion1 ** ## Transfer.hx1 . ## `age[50,60)` *** ## `age[60,70)` *** ## `age[70,80)` *** ## `age[80, Inf)` *** ## sexFemale *** ## DASIndex *** ## APACHE.score *** ## Glasgow.Coma.Score *** ## WBC ## Temperature ** ## PaO2vs.FIO2 ## Hematocrit *** ## Bilirubin *** ## Weight ** ## DNR.statusYes *** ## Medical.insuranceMedicare *** ## `Medical.insuranceMedicare &amp; Medicaid` * ## `Medical.insuranceNo insurance` * ## Medical.insurancePrivate * ## `Medical.insurancePrivate &amp; Medicare` * ## Respiratory.DiagYes . ## Cardiovascular.DiagYes * ## Neurological.DiagYes *** ## Gastrointestinal.DiagYes ** ## Hematologic.DiagYes *** ## Sepsis.DiagYes ## `incomeUnder $11k` ** ## RHC.use *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 7433.3 on 5734 degrees of freedom ## Residual deviance: 6198.0 on 5696 degrees of freedom ## AIC: 6276 ## ## Number of Fisher Scoring iterations: 5 "],["supervised-learning.html", "Chapter 6 Supervised Learning 6.1 Read previously saved data 6.2 Continuous outcome 6.3 Binary outcome 6.4 Ensemble methods (Type I) 6.5 Ensemble methods (Type II)", " Chapter 6 Supervised Learning In this chapter, we will move beyond statistical regression, and introduce some of the popular machine learning methods. 6.1 Read previously saved data ObsData &lt;- readRDS(file = &quot;data/rhcAnalytic.RDS&quot;) levels(ObsData$Death)=c(&quot;No&quot;,&quot;Yes&quot;) out.formula1 &lt;- readRDS(file = &quot;data/form1.RDS&quot;) out.formula2 &lt;- readRDS(file = &quot;data/form2.RDS&quot;) 6.2 Continuous outcome 6.2.1 Cross-validation LASSO ctrl &lt;- trainControl(method = &quot;cv&quot;, number = 5) fit.cv.con &lt;- train(out.formula1, trControl = ctrl, data = ObsData, method = &quot;glmnet&quot;, lambda= 0, tuneGrid = expand.grid(alpha = 1, lambda = 0), verbose = FALSE) fit.cv.con ## glmnet ## ## 5735 samples ## 50 predictor ## ## No pre-processing ## Resampling: Cross-Validated (5 fold) ## Summary of sample sizes: 4588, 4587, 4587, 4589, 4589 ## Resampling results: ## ## RMSE Rsquared MAE ## 25.14179 0.05746966 15.20167 ## ## Tuning parameter &#39;alpha&#39; was held constant at a value of 1 ## Tuning ## parameter &#39;lambda&#39; was held constant at a value of 0 6.2.2 Cross-validation Ridge ctrl &lt;- trainControl(method = &quot;cv&quot;, number = 5) fit.cv.con &lt;-train(out.formula1, trControl = ctrl, data = ObsData, method = &quot;glmnet&quot;, lambda= 0, tuneGrid = expand.grid(alpha = 0, lambda = 0), verbose = FALSE) fit.cv.con ## glmnet ## ## 5735 samples ## 50 predictor ## ## No pre-processing ## Resampling: Cross-Validated (5 fold) ## Summary of sample sizes: 4588, 4589, 4587, 4588, 4588 ## Resampling results: ## ## RMSE Rsquared MAE ## 25.0993 0.05746023 15.22744 ## ## Tuning parameter &#39;alpha&#39; was held constant at a value of 0 ## Tuning ## parameter &#39;lambda&#39; was held constant at a value of 0 6.3 Binary outcome 6.3.1 Cross-validation LASSO ctrl&lt;-trainControl(method = &quot;cv&quot;, number = 5, classProbs = TRUE, summaryFunction = twoClassSummary) fit.cv.bin&lt;-train(out.formula2, trControl = ctrl, data = ObsData, method = &quot;glmnet&quot;, lambda= 0, tuneGrid = expand.grid(alpha = 1, lambda = 0), verbose = FALSE, metric=&quot;ROC&quot;) fit.cv.bin ## glmnet ## ## 5735 samples ## 50 predictor ## 2 classes: &#39;No&#39;, &#39;Yes&#39; ## ## No pre-processing ## Resampling: Cross-Validated (5 fold) ## Summary of sample sizes: 4588, 4588, 4589, 4588, 4587 ## Resampling results: ## ## ROC Sens Spec ## 0.7546214 0.4634742 0.8535823 ## ## Tuning parameter &#39;alpha&#39; was held constant at a value of 1 ## Tuning ## parameter &#39;lambda&#39; was held constant at a value of 0 Not okay to select variables from a shrinkage model, and then use them in a regular regression 6.3.2 Cross-validation Ridge ctrl&lt;-trainControl(method = &quot;cv&quot;, number = 5, classProbs = TRUE, summaryFunction = twoClassSummary) fit.cv.bin&lt;-train(out.formula2, trControl = ctrl, data = ObsData, method = &quot;glmnet&quot;, lambda= 0, tuneGrid = expand.grid(alpha = 0, lambda = 0), verbose = FALSE, metric=&quot;ROC&quot;) fit.cv.bin ## glmnet ## ## 5735 samples ## 50 predictor ## 2 classes: &#39;No&#39;, &#39;Yes&#39; ## ## No pre-processing ## Resampling: Cross-Validated (5 fold) ## Summary of sample sizes: 4588, 4589, 4588, 4587, 4588 ## Resampling results: ## ## ROC Sens Spec ## 0.7528764 0.4610002 0.8524987 ## ## Tuning parameter &#39;alpha&#39; was held constant at a value of 0 ## Tuning ## parameter &#39;lambda&#39; was held constant at a value of 0 6.3.3 Cross-validation Elastic net Alpha = mixing parameter Lambda = regularization or tuning parameter We can use expand.grid for model tuning ctrl&lt;-trainControl(method = &quot;cv&quot;, number = 5, classProbs = TRUE, summaryFunction = twoClassSummary) fit.cv.bin&lt;-train(out.formula2, trControl = ctrl, data = ObsData, method = &quot;glmnet&quot;, tuneGrid = expand.grid(alpha = seq(0.1,.2,by = 0.05), lambda = seq(0.05,0.3,by = 0.05)), verbose = FALSE, metric=&quot;ROC&quot;) fit.cv.bin ## glmnet ## ## 5735 samples ## 50 predictor ## 2 classes: &#39;No&#39;, &#39;Yes&#39; ## ## No pre-processing ## Resampling: Cross-Validated (5 fold) ## Summary of sample sizes: 4587, 4588, 4588, 4588, 4589 ## Resampling results across tuning parameters: ## ## alpha lambda ROC Sens Spec ## 0.10 0.05 0.7530058 0.3695986568 0.8965624 ## 0.10 0.10 0.7493765 0.2742170043 0.9336408 ## 0.10 0.15 0.7445050 0.1748601904 0.9677600 ## 0.10 0.20 0.7388230 0.0894189104 0.9871036 ## 0.10 0.25 0.7322015 0.0253323951 0.9959703 ## 0.10 0.30 0.7254256 0.0019863462 0.9997315 ## 0.15 0.05 0.7519700 0.3537017148 0.9035477 ## 0.15 0.10 0.7453497 0.2200659235 0.9529844 ## 0.15 0.15 0.7356439 0.1023307779 0.9849553 ## 0.15 0.20 0.7247385 0.0178820538 0.9959695 ## 0.15 0.25 0.7170856 0.0004962779 0.9997315 ## 0.15 0.30 0.7107273 0.0000000000 1.0000000 ## 0.20 0.05 0.7507079 0.3328284138 0.9140258 ## 0.20 0.10 0.7394339 0.1693974297 0.9674904 ## 0.20 0.15 0.7242395 0.0372492377 0.9919405 ## 0.20 0.20 0.7140885 0.0014900683 0.9997315 ## 0.20 0.25 0.7069905 0.0000000000 1.0000000 ## 0.20 0.30 0.6971477 0.0000000000 1.0000000 ## ## ROC was used to select the optimal model using the largest value. ## The final values used for the model were alpha = 0.1 and lambda = 0.05. plot(fit.cv.bin) 6.3.4 Decision tree Decision tree Referred to as Classification and regression trees or CART Covers Classification (categorical outcome) Regression (continuous outcome) Flexible to incorporate non-linear effects automatically No need to specify higher order terms / interactions Unstable, prone to overfitting, suffers from high variance 6.3.4.1 Simple CART require(rpart) summary(ObsData$DASIndex) # Duke Activity Status Index ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 11.00 16.06 19.75 20.50 23.43 33.00 cart.fit &lt;- rpart(Death~DASIndex, data = ObsData) par(mfrow = c(1,1), xpd = NA) plot(cart.fit) text(cart.fit, use.n = TRUE) print(cart.fit) ## n= 5735 ## ## node), split, n, loss, yval, (yprob) ## * denotes terminal node ## ## 1) root 5735 2013 Yes (0.3510026 0.6489974) ## 2) DASIndex&gt;=24.92383 1143 514 No (0.5503062 0.4496938) ## 4) DASIndex&gt;=29.14648 561 199 No (0.6452763 0.3547237) * ## 5) DASIndex&lt; 29.14648 582 267 Yes (0.4587629 0.5412371) * ## 3) DASIndex&lt; 24.92383 4592 1384 Yes (0.3013937 0.6986063) * require(rattle) require(rpart.plot) require(RColorBrewer) fancyRpartPlot(cart.fit, caption = NULL) 6.3.4.1.1 AUC require(pROC) obs.y2&lt;-ObsData$Death pred.y2 &lt;- as.numeric(predict(cart.fit, type = &quot;prob&quot;)[, 2]) rocobj &lt;- roc(obs.y2, pred.y2) ## Setting levels: control = No, case = Yes ## Setting direction: controls &lt; cases rocobj ## ## Call: ## roc.default(response = obs.y2, predictor = pred.y2) ## ## Data: pred.y2 in 2013 controls (obs.y2 No) &lt; 3722 cases (obs.y2 Yes). ## Area under the curve: 0.5912 plot(rocobj) auc(rocobj) ## Area under the curve: 0.5912 6.3.4.2 Complex CART More variables out.formula2 ## Death ~ Disease.category + Cancer + Cardiovascular + Congestive.HF + ## Dementia + Psychiatric + Pulmonary + Renal + Hepatic + GI.Bleed + ## Tumor + Immunosupperssion + Transfer.hx + MI + age + sex + ## edu + DASIndex + APACHE.score + Glasgow.Coma.Score + blood.pressure + ## WBC + Heart.rate + Respiratory.rate + Temperature + PaO2vs.FIO2 + ## Albumin + Hematocrit + Bilirubin + Creatinine + Sodium + ## Potassium + PaCo2 + PH + Weight + DNR.status + Medical.insurance + ## Respiratory.Diag + Cardiovascular.Diag + Neurological.Diag + ## Gastrointestinal.Diag + Renal.Diag + Metabolic.Diag + Hematologic.Diag + ## Sepsis.Diag + Trauma.Diag + Orthopedic.Diag + race + income + ## RHC.use require(rpart) cart.fit &lt;- rpart(out.formula2, data = ObsData) 6.3.4.2.1 CART Variable importance cart.fit$variable.importance ## DASIndex Cancer Tumor age ## 123.2102455 33.4559400 32.5418433 24.0804860 ## Medical.insurance WBC edu Cardiovascular.Diag ## 14.5199953 5.6673997 3.7441554 3.6449371 ## Heart.rate Cardiovascular Trauma.Diag PaCo2 ## 3.4059248 3.1669125 0.5953098 0.2420672 ## Potassium Sodium Albumin ## 0.2420672 0.2420672 0.1984366 6.3.4.2.2 AUC require(pROC) obs.y2&lt;-ObsData$Death pred.y2 &lt;- as.numeric(predict(cart.fit, type = &quot;prob&quot;)[, 2]) rocobj &lt;- roc(obs.y2, pred.y2) ## Setting levels: control = No, case = Yes ## Setting direction: controls &lt; cases rocobj ## ## Call: ## roc.default(response = obs.y2, predictor = pred.y2) ## ## Data: pred.y2 in 2013 controls (obs.y2 No) &lt; 3722 cases (obs.y2 Yes). ## Area under the curve: 0.5981 plot(rocobj) auc(rocobj) ## Area under the curve: 0.5981 6.3.4.3 Cross-validation CART set.seed(504) require(caret) ctrl&lt;-trainControl(method = &quot;cv&quot;, number = 5, classProbs = TRUE, summaryFunction = twoClassSummary) # fit the model with formula = out.formula2 fit.cv.bin&lt;-train(out.formula2, trControl = ctrl, data = ObsData, method = &quot;rpart&quot;, metric=&quot;ROC&quot;) fit.cv.bin ## CART ## ## 5735 samples ## 50 predictor ## 2 classes: &#39;No&#39;, &#39;Yes&#39; ## ## No pre-processing ## Resampling: Cross-Validated (5 fold) ## Summary of sample sizes: 4587, 4589, 4587, 4589, 4588 ## Resampling results across tuning parameters: ## ## cp ROC Sens Spec ## 0.007203179 0.6304911 0.2816488 0.9086574 ## 0.039741679 0.5725283 0.2488649 0.8981807 ## 0.057128664 0.5380544 0.1287804 0.9473284 ## ## ROC was used to select the optimal model using the largest value. ## The final value used for the model was cp = 0.007203179. # extract results from each test data summary.res &lt;- fit.cv.bin$resample summary.res ## ROC Sens Spec Resample ## 1 0.6847220 0.3746898 0.8590604 Fold1 ## 2 0.6729625 0.2985075 0.8924731 Fold2 ## 3 0.6076153 0.2754342 0.9287634 Fold5 ## 4 0.5873154 0.2238806 0.9274194 Fold4 ## 5 0.5998401 0.2357320 0.9355705 Fold3 6.4 Ensemble methods (Type I) Training same model to different samples (of the same data) 6.4.1 Cross-validation bagging Bagging or bootstrap aggregation independent bootstrap samples (sampling with replacement, B times), applies CART on each i (no prunning) Average the resulting predictions Reduces variance as a result of using bootstrap set.seed(504) require(caret) ctrl&lt;-trainControl(method = &quot;cv&quot;, number = 5, classProbs = TRUE, summaryFunction = twoClassSummary) # fit the model with formula = out.formula2 fit.cv.bin&lt;-train(out.formula2, trControl = ctrl, data = ObsData, method = &quot;bag&quot;, bagControl = bagControl(fit = ldaBag$fit, predict = ldaBag$pred, aggregate = ldaBag$aggregate), metric=&quot;ROC&quot;) ## Warning: executing %dopar% sequentially: no parallel backend registered fit.cv.bin ## Bagged Model ## ## 5735 samples ## 50 predictor ## 2 classes: &#39;No&#39;, &#39;Yes&#39; ## ## No pre-processing ## Resampling: Cross-Validated (5 fold) ## Summary of sample sizes: 4587, 4589, 4587, 4589, 4588 ## Resampling results: ## ## ROC Sens Spec ## 0.7506666 0.4485809 0.8602811 ## ## Tuning parameter &#39;vars&#39; was held constant at a value of 63 bagging improves prediction accuracy over prediction using a single tree Looses interpretability as this is an average of many diagrams now But we can get a summary of the importance of each variable 6.4.1.1 Bagging Variable importance caret::varImp(fit.cv.bin, scale = FALSE) ## ROC curve variable importance ## ## only 20 most important variables shown (out of 50) ## ## Importance ## age 0.6159 ## APACHE.score 0.6140 ## DASIndex 0.5962 ## Cancer 0.5878 ## Creatinine 0.5835 ## Tumor 0.5807 ## blood.pressure 0.5697 ## Glasgow.Coma.Score 0.5656 ## Disease.category 0.5641 ## Temperature 0.5584 ## DNR.status 0.5572 ## Hematocrit 0.5525 ## Weight 0.5424 ## Bilirubin 0.5397 ## income 0.5319 ## Immunosupperssion 0.5278 ## RHC.use 0.5263 ## Dementia 0.5252 ## Congestive.HF 0.5250 ## Hematologic.Diag 0.5250 6.4.2 Cross-validation boosting Boosting sequentially updated/weighted bootstrap based on previous learning set.seed(504) require(caret) ctrl&lt;-trainControl(method = &quot;cv&quot;, number = 5, classProbs = TRUE, summaryFunction = twoClassSummary) # fit the model with formula = out.formula2 fit.cv.bin&lt;-train(out.formula2, trControl = ctrl, data = ObsData, method = &quot;gbm&quot;, verbose = FALSE, metric=&quot;ROC&quot;) fit.cv.bin ## Stochastic Gradient Boosting ## ## 5735 samples ## 50 predictor ## 2 classes: &#39;No&#39;, &#39;Yes&#39; ## ## No pre-processing ## Resampling: Cross-Validated (5 fold) ## Summary of sample sizes: 4587, 4589, 4587, 4589, 4588 ## Resampling results across tuning parameters: ## ## interaction.depth n.trees ROC Sens Spec ## 1 50 0.7218938 0.2145970 0.9505647 ## 1 100 0.7410292 0.2980581 0.9234228 ## 1 150 0.7483014 0.3487142 0.9030028 ## 2 50 0.7414513 0.2960631 0.9263816 ## 2 100 0.7534264 0.3869684 0.8917212 ## 2 150 0.7575826 0.4187512 0.8777477 ## 3 50 0.7496078 0.3626125 0.9070358 ## 3 100 0.7579645 0.4078244 0.8764076 ## 3 150 0.7637074 0.4445909 0.8702298 ## ## Tuning parameter &#39;shrinkage&#39; was held constant at a value of 0.1 ## ## Tuning parameter &#39;n.minobsinnode&#39; was held constant at a value of 10 ## ROC was used to select the optimal model using the largest value. ## The final values used for the model were n.trees = 150, interaction.depth = ## 3, shrinkage = 0.1 and n.minobsinnode = 10. plot(fit.cv.bin) 6.5 Ensemble methods (Type II) Training different models on the same data 6.5.1 Super Learner Large number of candidate learners (CL) with different strengths Parametric (logistic) Non-parametric (CART) Cross-validation: CL applied on training data, prediction made on test data Final prediction uses a weighted version of all predictions Weights = coef of Observed outcome ~ prediction from each CL 6.5.2 Steps Refer to this tutorial for steps and examples! "],["unsupervised-learning.html", "Chapter 7 Unsupervised Learning 7.1 K-means 7.2 Read previously saved data 7.3 Optimal number of clusters 7.4 Discussion", " Chapter 7 Unsupervised Learning Clustering is an unsupervised learning algorithm. These algorithms can classify data into multiple groups. Such classification is based on similarity. Group characteristics include (to the extent that is possible) low inter-class similarity: observation from different clusters would be dissimilar high intra-class similarity: observation from the same cluster would be similar Within-cluster variation will be thus minimized by optimizing within-cluster sum of squares of Euclidean distances (ref) 7.1 K-means K-means is a very popular clustering algorithm, that partitions the data into \\(k\\) groups. Algorithm: Determine a number \\(k\\) (e.g., could be 3) randomly select \\(k\\) subjects in a data. Use these points as staring points (centers or cluster mean) for each cluster. By Euclidean distance measure (from the initial centers), try to determine in which cluster the remaining points belong. compute new mean value for each cluster. based on this new mean, try to determine again in which cluster the data points belong. process continues until the data points do not change cluster membership. 7.2 Read previously saved data ObsData &lt;- readRDS(file = &quot;data/rhcAnalytic.RDS&quot;) 7.2.1 Example 1 datax0 &lt;- ObsData[c(&quot;Heart.rate&quot;, &quot;edu&quot;)] kres0 &lt;- kmeans(datax0, centers = 2, nstart = 10) kres0$centers ## Heart.rate edu ## 1 54.55138 11.44494 ## 2 134.96277 11.75466 plot(datax0, col = kres0$cluster, main = kres0$tot.withinss) 7.2.2 Example 2 datax0 &lt;- ObsData[c(&quot;blood.pressure&quot;, &quot;Heart.rate&quot;, &quot;Respiratory.rate&quot;)] kres0 &lt;- kmeans(datax0, centers = 2, nstart = 10) kres0$centers ## blood.pressure Heart.rate Respiratory.rate ## 1 80.10812 135.08956 29.85267 ## 2 73.71684 54.95789 22.76723 plot(datax0, col = kres0$cluster, main = kres0$tot.withinss) 7.2.3 Example with many variables datax &lt;- ObsData[c(&quot;edu&quot;, &quot;blood.pressure&quot;, &quot;Heart.rate&quot;, &quot;Respiratory.rate&quot; , &quot;Temperature&quot;, &quot;PH&quot;, &quot;Weight&quot;, &quot;Length.of.Stay&quot;)] kres &lt;- kmeans(datax, centers = 3) #kres head(kres$cluster) ## [1] 1 1 1 3 1 2 kres$size ## [1] 2793 1688 1254 kres$centers ## edu blood.pressure Heart.rate Respiratory.rate Temperature PH ## 1 11.85833 54.26924 136.37451 29.76119 37.85078 7.385249 ## 2 11.54214 128.33886 126.12026 29.36611 37.68129 7.401027 ## 3 11.46134 65.47249 53.24242 22.65973 37.01597 7.378482 ## Weight Length.of.Stay ## 1 68.63384 23.42356 ## 2 66.68351 20.68128 ## 3 67.57291 18.58931 aggregate(datax, by = list(cluster = kres$cluster), mean) ## cluster edu blood.pressure Heart.rate Respiratory.rate Temperature ## 1 1 11.85833 54.26924 136.37451 29.76119 37.85078 ## 2 2 11.54214 128.33886 126.12026 29.36611 37.68129 ## 3 3 11.46134 65.47249 53.24242 22.65973 37.01597 ## PH Weight Length.of.Stay ## 1 7.385249 68.63384 23.42356 ## 2 7.401027 66.68351 20.68128 ## 3 7.378482 67.57291 18.58931 aggregate(datax, by = list(cluster = kres$cluster), sd) ## cluster edu blood.pressure Heart.rate Respiratory.rate Temperature ## 1 1 3.162485 11.93763 23.13140 13.67791 1.781692 ## 2 2 3.091605 18.58070 27.68369 14.08169 1.610746 ## 3 3 3.160538 31.89150 23.63993 13.60831 1.832389 ## PH Weight Length.of.Stay ## 1 0.1082140 27.99506 29.01143 ## 2 0.1009567 32.15078 23.37223 ## 3 0.1226041 26.87075 20.82024 7.3 Optimal number of clusters require(factoextra) fviz_nbclust(datax, kmeans, method = &quot;wss&quot;)+ geom_vline(xintercept=3,linetype=3) Here the vertical line is chosen based on elbow method (ref). 7.4 Discussion We need to supply a number, \\(k\\): but we can test different \\(k\\)s to identify optimal value Clustering can be influenced by outliners, so median based clustering is possible mere ordering can influence clustering, hence we should choose different initial means (e.g., nstart should be greater than 1). "],["references.html", "References", " References "]]
