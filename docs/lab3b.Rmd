---
title: "SPPH 507 Section 007 Lab 3: Avoiding overfitting"
author:
- affiliation: School of Population and Publich Health, UBC
  name: Ehsan Karim
output:
  html_document:
    fig_caption: yes
    keep_md: yes
    toc: yes
    number_sections: true
    toc_depth: 2
    toc_float: 
      collapsed: true
      smooth_scroll: true
    theme: lumen
    highlight: textmate
  pdf_document:
    fig_caption: yes
    latex_engine: xelatex
    number_sections: yes
    toc: yes
    toc_depth: 3
  word_document:
    toc: yes
  slidy_presentation:
    toc: yes  
---

```{r setup, include=FALSE}
# if still not installed, try install.packages("PackageName")
knitr::opts_chunk$set(echo = TRUE)
require(DescTools)
require(caret)
require(knitr)
```

# Load data

Load the data saved at the end of previous part of the lab.

```{r}
load(file="cholesterolNHANES15part1.RData")
#head(analytic)
str(analytic)
str(analytic3)
```

Fit the final model that we decided at the end of previous part of the lab.

```{r}
formula4 <- as.formula("cholesterol~gender + age + born + 
             race + education + married + 
             income + diastolicBP + systolicBP + 
             bmi +
             triglycerides + uric.acid + 
             protein + bilirubin + phosphorus + sodium + potassium + 
             globulin + calcium + physical.work + physical.recreational + 
             diabetes")
formula4
fit4 <- lm(formula4, data = analytic3)
summary(fit4)
```

# Design Matrix

Expands factors to a set of dummy variables.

```{r}
head(model.matrix(fit4))
dim(model.matrix(fit4))
p <- dim(model.matrix(fit4))[2] # intercept + slopes
p
```

# Check prediction

```{r}
obs.y <- analytic3$cholesterol
summary(obs.y)
# Predict the above fit on analytic3 data
pred.y <- predict(fit4, analytic3)
summary(pred.y)
n <- length(pred.y)
n
plot(obs.y,pred.y)
lines(lowess(obs.y,pred.y), col = "red")
# Prediction on a new data: fictitious.data
str(fictitious.data)
pred.y.new1 <- predict(fit4, fictitious.data)
summary(pred.y.new1)
```

## Measuring prediction error

Continuous outcomes

### R2

[ref](https://en.wikipedia.org/wiki/Coefficient_of_determination)

```{r ubc8, echo=FALSE, out.width = '90%'}
knitr::include_graphics("r2.png")
```

```{r}
# Find SSE
SSE <- sum( (obs.y - pred.y)^2 )
SSE
# Find SST
mean.obs.y <- mean(obs.y)
SST <- sum( (obs.y - mean.obs.y)^2 )
SST
# Find R2
R.2 <- 1- SSE/SST
R.2
require(caret)
R2(pred.y, obs.y)
```

### RMSE

[ref](https://en.wikipedia.org/wiki/One-way_analysis_of_variance)

```{r ubc89, echo=FALSE, out.width = '90%'}
knitr::include_graphics("rmse.png")
```

```{r}
# Find RMSE
Rmse <- sqrt(SSE/(n-p)) 
Rmse
RMSE(pred.y, obs.y)
```

### Adj R2

[ref](https://en.wikipedia.org/wiki/Coefficient_of_determination#Adjusted_R2)

```{r ubc899, echo=FALSE, out.width = '30%'}
knitr::include_graphics("r2a.png")
```

```{r}
# Find adj R2
adjR2 <- 1-(1-R.2)*((n-1)/(n-p))
adjR2
```

## Writing function

### Syntax for Writing Functions

```{r, eval=FALSE}
func_name <- function (argument) {
  A statement or multiple lines of statements
  return(output)
}
```

### Example of a simple function

```{r}
f1 <- function(a,b){
  result <- a + b
  return(result)
}
f1(a=1,b=3)
f1(a=1,b=6)
# setting default values
f1 <- function(a=1,b=1){
  result <- a + b
  return(result)
}
f1()
f1(b = 10)
```

### A bit more complicated

```{r}
# one argument
model.fit <- function(data.for.fitting){
  formulax <- as.formula("cholesterol~gender + age + born")
  fitx <- lm(formulax, data = data.for.fitting)
  result <- coef(fitx)
  return(result)
}
model.fit(data.for.fitting=analytic)
model.fit(data.for.fitting=analytic3)
```

```{r}
# adding one more argument: digits
model.fit <- function(data.for.fitting, digits=2){
  formulax <- as.formula("cholesterol~gender + age + born")
  fitx <- lm(formulax, data = data.for.fitting)
  result <- coef(fitx)
  result <- round(result,digits)
  return(result)
}
model.fit(data.for.fitting=analytic)
model.fit(data.for.fitting=analytic3)
```


### Function that gives performance measures
```{r}
perform <- function(new.data,
                    model.fit,model.formula=NULL, 
                    y.name = "Y",
                    digits=3){
  # data dimension
  p <- dim(model.matrix(model.fit))[2]
  # predicted value
  pred.y <- predict(model.fit, new.data)
  # sample size
  n <- length(pred.y)
  # outcome
  new.data.y <- as.numeric(new.data[,y.name])
  # R2
  R2 <- caret:::R2(pred.y, new.data.y)
  # adj R2 using alternate formula
  df.residual <- n-p
  adjR2 <- 1-(1-R2)*((n-1)/df.residual)
  # RMSE
  RMSE <-  caret:::RMSE(pred.y, new.data.y)
  # combine all of the results
  res <- round(cbind(n,p,R2,adjR2,RMSE),digits)
  # returning object
  return(res)
}
perform(new.data=analytic3,y.name = "cholesterol",model.fit=fit4)
```


# Data spliting

[ref](https://www.kdnuggets.com/2020/05/dataset-splitting-best-practices-python.html)

```{r c674, echo=FALSE, out.width = '90%'}
knitr::include_graphics("tts.jpg")
```

[ref](https://topepo.github.io/caret/data-splitting.html)

```{r}
# Using a seed to randomize in a reproducible way 
set.seed(123)
split<-createDataPartition(y = analytic3$cholesterol, p = 0.7, list = FALSE)
str(split)
dim(split)
dim(analytic3)*.7 # approximate train data
dim(analytic3)*(1-.7) # approximate train data
```

## Split the data 
```{r}
# create train data
train.data<-analytic3[split,]
dim(train.data)
# create test data
test.data<-analytic3[-split,]
dim(test.data)
```

## Train the model
```{r}
formula4
fit4.train1<-lm(formula4, data = train.data)
summary(fit4.train1)
```

## Extract performance measures
```{r}
perform(new.data=train.data,y.name = "cholesterol",model.fit=fit4.train1)
perform(new.data=test.data,y.name = "cholesterol",model.fit=fit4.train1)
perform(new.data=analytic3,y.name = "cholesterol",model.fit=fit4.train1)
perform(new.data=fictitious.data,y.name = "cholesterol",model.fit=fit4.train1)
```


[ref](https://topepo.github.io/caret/model-training-and-tuning.html)

```{r c869, echo=FALSE, out.width = '90%'}
knitr::include_graphics("TrainAlgo.png")
```

# k-fold cross-vaildation

[ref](https://en.wikipedia.org/wiki/Cross-validation_(statistics))

```{r c954, echo=FALSE, out.width = '90%'}
knitr::include_graphics("kf.png")
```

```{r}
k = 5
dim(analytic3)
set.seed(567)
# create folds (based on outcome)
folds <- createFolds(analytic3$cholesterol, k = k, 
                     list = TRUE, returnTrain = TRUE)
mode(folds)
dim(analytic3)*4/5 # approximate training data size
dim(analytic3)/5  # approximate test data size
length(folds[[1]])
length(folds[[2]])
length(folds[[3]])
length(folds[[4]])
length(folds[[5]])
str(folds[[1]])
str(folds[[2]])
str(folds[[3]])
str(folds[[4]])
str(folds[[5]])
```

## Calculation for Fold 1
```{r}
fold.index <- 1
fold1.train.ids <- folds[[fold.index]]
head(fold1.train.ids)
fold1.train <- analytic3[fold1.train.ids,]
fold1.test <- analytic3[-fold1.train.ids,]
formula4
model.fit <- lm(formula4, data = fold1.train)
predictions <- predict(model.fit, 
                       newdata = fold1.test)
perform(new.data=fold1.test,
        y.name = "cholesterol",
        model.fit=model.fit)
```

## Calculation for Fold 2
```{r}
fold.index <- 2
fold1.train.ids <- folds[[fold.index]]
head(fold1.train.ids)
fold1.train <- analytic3[fold1.train.ids,]
fold1.test <- analytic3[-fold1.train.ids,]
model.fit <- lm(formula4, data = fold1.train)
predictions <- predict(model.fit, 
                       newdata = fold1.test)
perform(new.data=fold1.test,
        y.name = "cholesterol",
        model.fit=model.fit)
```

## Using caret package to automate

[ref](https://topepo.github.io/caret/model-training-and-tuning.html)

```{r cv, cache= TRUE}
# Using Caret package
set.seed(567)
# make a 5-fold CV
ctrl<-trainControl(method = "cv",number = 5)
# fit the model with formula = formula4
# use training method lm
fit4.cv<-train(formula4, trControl = ctrl,
               data = analytic3, method = "lm")
fit4.cv
# extract results from each test data 
summary.res <- fit4.cv$resample
summary.res
mean(fit4.cv$resample$Rsquared)
sd(fit4.cv$resample$Rsquared)
# # extract adj R2
# k <- 5
# p <- 2
# n <- round(nrow(analytic3)/k)
# summary.res$adjR2 <- 1-(1-fit4.cv$resample$Rsquared)*((n-1)/(n-p))
# summary.res
```


# Bootstrap

## Resampling a vector

```{r}
fake.data <- 1:5
fake.data
```
```{r}
resampled.fake.data <- sample(fake.data, size = length(fake.data), replace = TRUE)
resampled.fake.data
selected.fake.data <- unique(resampled.fake.data)
selected.fake.data
fake.data[!(fake.data %in% selected.fake.data)]
```
The samples not selected are known as the out-of-bag samples



```{r}
B <- 10
for (i in 1:B){
  new.boot.sample <- sample(fake.data, size = length(fake.data), replace = TRUE)
  print(new.boot.sample)
}
```
## Calculating SD of a statistics

Idea:

 - Not sure about what distribution is appropriate to make inference?
 - If that is the case, calculating CI is hard.
 - resample and get a new bootstrap sample
 - calculate a statistic (say, mean) from that sample
 - find SD of those statistic (say, means)
 - Use those SD to calculate CI

```{r}
mean(fake.data)
B <- 5
resamples <- lapply(1:B, function(i) sample(fake.data, replace = TRUE))
str(resamples)
B.means <- sapply(resamples, mean)
B.means
mean(B.means)
# SD of the distribution of means
sd(B.means)
```

```{r}
mean(fake.data)
B <- 200
resamples <- lapply(1:B, function(i) sample(fake.data, replace = TRUE))
# str(resamples)
B.means <- sapply(resamples, mean)
B.medians <- sapply(resamples, median)
mean(B.means)
# SD of the distribution of means
sd(B.means)
mean(B.medians)
hist(B.means)
# SD of the distribution of medians
sd(B.medians)
hist(B.medians)
```


## Resampling a data or matrix

```{r}
analytic.mini <- head(analytic)
kable(analytic.mini[,1:3])
```
```{r}
analytic.boot <- analytic.mini[sample(x = 1:nrow(analytic.mini), 
                                      size = nrow(analytic.mini), 
                                      replace = TRUE), ]
kable(analytic.boot[,1:3])
selected.subjects <- unique(analytic.boot$ID)
selected.subjects
# out-of-bag samples
analytic.mini$ID[!(analytic.mini$ID %in% selected.subjects)]
```
```{r}
analytic.boot <- analytic.mini[sample(x = 1:nrow(analytic.mini), 
                                      size = nrow(analytic.mini), 
                                      replace = TRUE), ]
kable(analytic.boot[,1:3])
selected.subjects <- unique(analytic.boot$ID)
selected.subjects
# out-of-bag samples
analytic.mini$ID[!(analytic.mini$ID %in% selected.subjects)]
```


## The caret package / boot

Usually B = 200 or 500 is recommended, but we will do 50 for the lab (to save time).

```{r b206, cache= TRUE}
set.seed(234)
ctrl<-trainControl(method = "boot", number = 50)
fit4.boot2<-train(formula4, trControl = ctrl,
                  data = analytic3, method = "lm")
fit4.boot2
head(fit4.boot2$resample)
mean(fit4.boot2$resample$Rsquared)
sd(fit4.boot2$resample$Rsquared)
```

## Method boot632
```{r b2, cache= TRUE}
ctrl<-trainControl(method = "boot632", number = 50)
fit4.boot2b<-train(formula4, trControl = ctrl,
                  data = analytic3, method = "lm")
fit4.boot2b
head(fit4.boot2b$resample)
mean(fit4.boot2b$resample$Rsquared)
sd(fit4.boot2b$resample$Rsquared)
```

## Method boot632 for stepwise 

### A stable model

[ref](https://topepo.github.io/caret/available-models.html)

Bias is reduced with 632 bootstrap, but may provide unstable results with a small samples size.

```{r b3, cache= TRUE}
ctrl<-trainControl(method = "boot632", number = 50)
fit4.boot2b<-train(formula4, trControl = ctrl,
                  data = analytic3, method = "lmStepAIC", trace = 0)
fit4.boot2b
head(fit4.boot2b$resample)
mean(fit4.boot2b$resample$Rsquared)
sd(fit4.boot2b$resample$Rsquared)
```

### An unstable model

```{r b4, cache= TRUE}
ctrl<-trainControl(method = "boot632", number = 50)
# formula3 includes collinear variables
fit4.boot2b<-train(formula3, trControl = ctrl,
                  data = analytic3, method = "lmStepAIC", trace = 0)
fit4.boot2b
head(fit4.boot2b$resample)
mean(fit4.boot2b$resample$Rsquared)
sd(fit4.boot2b$resample$Rsquared)
```

Note that SD should be higher for larger B.

## Optimism corrected bootstrap

[ref](https://rstudio-pubs-static.s3.amazonaws.com/90467_c70206f3dc864d53bf36072207ee011d.html)

```{r c89, echo=FALSE, out.width = '90%'}
knitr::include_graphics("ocb.png")
```

  - Fit a model M to entire data D and estimate predictive ability R2.
  - Iterate from b=1 to B:
     - Take a resample from the original data, and name it D.star
     - Fit the bootstrap model M.stat to D.star and get predictive ability, R2.boot
     - Use the bootstrap model M.star to get predictive ability on D, R2.fullData
  - Optimism Opt is calculated as mean(R2.boot - R2.fullData)
  - Calculate optimism corrected performance as R2-Opt.

```{r bo, cache= TRUE}
R2.opt <- function(data, fit, B, y.name = "cholesterol"){
  D <- data
  y.index <- which(names(D)==y.name)
  # M is the model fit to entire data D
  M <- fit
  pred.y <- predict(M, D)
  n <- length(pred.y)
  y <- as.numeric(D[,y.index])
  # estimate predictive ability R2.
  R2.app <- caret:::R2(pred.y, y)
  # create blank vectors to save results
  R2.boot <- vector (mode = "numeric", length = B)
  R2.fullData <- vector (mode = "numeric", length = B)
  opt <- vector (mode = "numeric", length = B)
  # Iterate from b=1 to B
  for(i in 1:B){    
    # Take a resample from the original data, and name it D.star
    boot.index <- sample(x=rownames(D), size=nrow(D), replace=TRUE)
    D.star <- D[boot.index,]
    M.star <- lm(formula(M), data = D.star)
    # Fit the bootstrap model M.stat to D.star and get predictive ability, R2.boot
    D.star$pred.y <- predict(M.star, new.data = D.star)
    y.index <- which(names(D.star)==y.name)
    D.star$y <- as.numeric(D.star[,y.index])
    R2.boot[i] <- caret:::R2(D.star$pred.y, D.star$y)
    # Use the bootstrap model M.star to get predictive ability on D, R2_fullData
    D$pred.y <- predict(M.star, newdata=D)
    R2.fullData[i] <- caret:::R2(D$pred.y, y)
    # Optimism Opt is calculated as R2.boot - R2.fullData
    opt[i] <- R2.boot[i] - R2.fullData[i]
  }
  boot.res <- round(cbind(R2.boot, R2.fullData,opt),2)
  # Calculate optimism corrected performance as R2- mean(Opt).
  R2.oc <- R2.app - (sum(opt)/B)
  return(list(R2.oc=R2.oc,R2.app=R2.app, boot.res = boot.res))
}
R2x <- R2.opt(data = analytic3, fit4, B=50)
R2x
```

# Binary outcome

AUC from  Receiver Operating Characteristic (ROC) = Measure of accuracy for classification models.

AUC = 1 (perfect classification)
AUC = 0.5 (random classification)

```{r bin, cache=TRUE}
set.seed(234)
formula5
# Bootstrap
ctrl<-trainControl(method = "boot", 
                   number = 50, 
                   classProbs=TRUE,
                   summaryFunction = twoClassSummary)
fit5.boot<-caret::train(formula5, 
                        trControl = ctrl,
                        data = analytic3, 
                        method = "glm", 
                        family="binomial",
                        metric="ROC")
fit5.boot
mean(fit5.boot$resample$ROC)
sd(fit5.boot$resample$ROC)
# CV
ctrl<-trainControl(method = "cv",
                   number = 5,
                   classProbs = TRUE, 
                   summaryFunction = twoClassSummary)
fit5.cv<-train(formula5, 
               trControl = ctrl,
               data = analytic3, 
               method = "glm", 
               family="binomial",
               metric="ROC")
fit5.cv
fit5.cv$resample
mean(fit5.cv$resample$ROC)
sd(fit5.cv$resample$ROC)
```

```{r}
require(DescTools)
fit5 <- glm(formula5, family = binomial(), data = analytic3)
BrierScore(fit5)
```

